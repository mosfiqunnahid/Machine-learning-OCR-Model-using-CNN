# -*- coding: utf-8 -*-
"""OCR Model using CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12W90tDBTL4YH46t4T8qeVuTmDz-gp7Sa
"""

import cv2
import keras
import imutils
import numpy as np
import pandas as pd
from keras import Sequential
from keras.layers import Dense
import matplotlib.pyplot as plt
from skimage.color import rgb2gray
from keras.models import Sequential
from keras.optimizers import Adam, SGD
from keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, ZeroPadding2D, BatchNormalization

x = np.load('/content/drive/My Drive/LICT training/Mosfiqun Nahid Hassan/Preprocessing_Data( Jupyter)/Numta64allx.npy')/255.0
y = np.load('/content/drive/My Drive/LICT training/Mosfiqun Nahid Hassan/Preprocessing_Data( Jupyter)/Numta64ally.npy')

x.shape

x = x.reshape(-1,64,64,1)
y = to_categorical(y)

x.shape

y.shape

model = Sequential()

model.add(Conv2D(64, (3, 3),padding='same', activation='relu', input_shape=(64, 64,1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128,(3,3),padding='same', activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(256,(3,3),padding='same', activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(512,(3,3),padding='same', activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(512,(3,3),padding='same', activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(4096, activation='relu'))
model.add(Dense(10, activation='softmax'))
adam = Adam(lr=.0001)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1)

datagen = ImageDataGenerator(rotation_range=5, width_shift_range=0.2, height_shift_range=0.2,  zoom_range=0.2)
datagen.fit(X_train)

history = model.fit(datagen.flow(X_train, y_train,batch_size=100),validation_data=(X_test, y_test),epochs=10)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model acc')
plt.ylabel('acc')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

model.save_weights('OCR_val_accuracy_9885.h5')

model.save('OCR_Model.h5')

all_img = []
for i in range(1,10):
  img1 = cv2.imread(str(i)+'.PNG',0)
  (thresh, im_bw) = cv2.threshold(img1, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
  inv = cv2.bitwise_not(im_bw)
  all_img.append(cv2.resize(inv, (64,64)))

all_img = np.array(all_img)

for i in range(1,10):
  plt.subplot(2,5,i)
  plt.imshow(all_img[i-1])
  plt.title(np.argmax(model.predict(np.reshape(all_img[i-1],(-1,64,64,1)))))

def segment(image, height=64):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (7, 7), 0)

    # threshold the image
    ret,thresh1 = cv2.threshold(gray ,100,255,cv2.THRESH_BINARY_INV)

    # dilate the white portions
    dilate = cv2.dilate(thresh1, None, iterations=2)

    # find contours in the image
    cnts = cv2.findContours(dilate.copy(), cv2.RETR_EXTERNAL,
        cv2.CHAIN_APPROX_SIMPLE)
    cnts = cnts[1] if imutils.is_cv2() else cnts[0]

    orig = image.copy()
    i = 0
    t = 0
    c=0
    x_all = []
    w_all = []
    lines = []
    parts = []

    for cnt in cnts:
        # Check the area of contour, if it is very small ignore it
        if(cv2.contourArea(cnt) < 100):
            continue

        # Filtered countours are detected
        x,y,w,h = cv2.boundingRect(cnt)
        x_all.append(x)
        w_all.append(w)
        i = i + 1 

    comb = np.zeros((2,len(x_all)))
    comb[0,:]=x_all
    comb[1,:]=w_all
    comb = comb.T
    comb = comb[comb[:,0].argsort()]

    x_all = comb[:,0]
    w_all = comb[:,1]


    for i, item in enumerate (x_all):
        if i < len(x_all)-1:
            lines.append((item+w_all[i]+x_all[i+1])/2)


    for i in range(len(lines)):
        parts.append(cv2.resize(image
                                [:,t:int(lines[i]),:],(height,height)))
        t = int(lines[i])
        if i == len(lines)-1:
            parts.append(cv2.resize(image[:,t:,:],(height,height)))
    
    return parts

img=cv2.imread('135.PNG')
img1=segment(img)
i=np.array(img1)
i.shape

all_img = []

for j in range (len(i)):
  img2=rgb2gray(i[j])
  all_img.append(img2)

result=[]
for j in range(len(i)):
  result.append(np.argmax(model.predict(np.reshape(all_img[j],(-1,64,64,1)))))
sum=""
for j in range(len(i)):
   sum=sum+str(result[j])
plt.imshow(img)
plt.title(sum)